{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitÃ©es.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "# We concentrate our study on the movements (entries & exits) during the fiscal years 2015 and 2016\n",
    "#movements = fandom[((fandom.Opening_date >= '2015-01-31') & (fandom.Opening_date <= '2017-01-31')) | ((fandom.Closing_date >= '2015-01-31') & (fandom.Closing_date <= '2017-01-31'))]\n",
    "# Correction des effets de bord M12\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\"MILK\"]\n",
    "nielsen['upc_price'] = nielsen.price_per_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hey = nielsen.groupby('product_group_descr').count()\n",
    "categories = hey[hey.is_walmart<25000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"FRESH PRODUCE\",\n",
    "    \"BREAD AND BAKED GOODS\",\n",
    "    \"MILK\",\n",
    "    \"SNACKS\",\n",
    "    \"PACKAGED MEATS-DELI\",\n",
    "    \"CHEESE\",\n",
    "    \"UNPREP MEAT/POULTRY/SEAFOOD-FRZN\",\n",
    "    \"CARBONATED BEVERAGES\",\n",
    "    \"CONDIMENTS, GRAVIES, AND SAUCES\",\n",
    "    \"CANDY\",\n",
    "    \"JUICE, DRINKS - CANNED, BOTTLED\",\n",
    "    \"EGGS\",\n",
    "    \"CEREAL\",\n",
    "    \"PASTA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =[\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"PACKAGED MILK AND MODIFIERS\",\n",
    "    \"SPICES, SEASONING, EXTRACTS\",\n",
    "    \"SUGAR, SWEETENERS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\n",
    "    \"BAKING MIXES\",\n",
    "    \"MILK\",\n",
    "    \"CHEESE\",\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"CRACKERS\"\n",
    "    \"CANDY\",\n",
    "    \"PASTA\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()\n",
    "\n",
    "categories = ['_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMIER MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Prices_{i, t} = \\alpha + \\beta treat_i + \\gamma treat_i* post_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.012243573513392336\n",
      "Coef/err : 3.053990985459992\n",
      "CI_up : 0.0043688770208243355\n",
      "CI_down : 0.020180011111512908\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.purchase_year > treatment.Opening_date.dt.year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction']]\n",
    "    df = df[df.upc_price != 0]\n",
    "    reg0 = smf.ols(formula='np.log(upc_price) ~ treat + interaction', data=df)\n",
    "    results0 = reg0.fit()\n",
    "    #if abs(results0.params[2] / results0.bse[2]) > 2. :\n",
    "    if True:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results0.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results0.params[2] / results0.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results0.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results0.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEUXIEME MODELE - monthly time fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.02223552240504789\n",
      "Coef/err : 1.4577683184459918\n",
      "CI_up : -0.0075483686655423154\n",
      "CI_down : 0.052913240579445686\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.Opening_date.dt.year > treatment.purchase_year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    if True :\n",
    "    #if  abs(results1.params[2] / results1.bse[2])> 2.:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TROISIEME MODELE - state effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "_\n",
      "Coef : 0.03341797594021911\n",
      "Coef/err : 2.3002084834970784\n",
      "CI_up : 0.004873365074778313\n",
      "CI_down : 0.06277343007982616\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) + C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if True:\n",
    "    #if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUATRIEME MODELE - state*time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel sâest bloquÃ© lors de lâexÃ©cution du code dans la cellule active ou une cellule prÃ©cÃ©dente. Veuillez vÃ©rifier le code dans la ou les cellules pour identifier une cause possible de lâÃ©chec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus dâinformations. Pour plus dâinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1751.\n",
      "Size of the control group: 701.\n",
      "Size of the control group: 460.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "CANDY\n",
      "Coef : 0.058063436001930535\n",
      "Coef/err : 3.8703008634540486\n",
      "CI_up : 0.028246807350231995\n",
      "CI_down : 0.08874467355666482\n",
      "Size of the control group: 1753.\n",
      "Size of the control group: 974.\n",
      "Size of the control group: 660.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "MILK\n",
      "Coef : -0.04109512362255707\n",
      "Coef/err : 5.162073822958096\n",
      "CI_up : -0.05625330864197686\n",
      "CI_down : -0.025693472241679283\n",
      "Size of the control group: 1610.\n",
      "Size of the control group: 450.\n",
      "Size of the control group: 246.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "COFFEE\n",
      "Coef : 0.03699238687960982\n",
      "Coef/err : 2.9354635273784924\n",
      "CI_up : 0.012139500147311244\n",
      "CI_down : 0.0624555313667321\n",
      "Size of the control group: 1699.\n",
      "Size of the control group: 648.\n",
      "Size of the control group: 393.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "PAPER PRODUCTS\n",
      "Coef : 0.10578211515236746\n",
      "Coef/err : 6.0283033645176305\n",
      "CI_up : 0.07021153549074\n",
      "CI_down : 0.14253495280272444\n",
      "Size of the control group: 1613.\n",
      "Size of the control group: 569.\n",
      "Size of the control group: 389.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "YOGURT\n",
      "Coef : 0.06032904640608816\n",
      "Coef/err : 2.80193903855756\n",
      "CI_up : 0.01775344934561196\n",
      "CI_down : 0.10468570494684859\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in ['CANDY', 'MILK', 'COFFEE', 'PAPER PRODUCTS', 'YOGURT']:\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    #product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 2]\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
