{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitées.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "# We concentrate our study on the movements (entries & exits) during the fiscal years 2015 and 2016\n",
    "#movements = fandom[((fandom.Opening_date >= '2015-01-31') & (fandom.Opening_date <= '2017-01-31')) | ((fandom.Closing_date >= '2015-01-31') & (fandom.Closing_date <= '2017-01-31'))]\n",
    "# Correction des effets de bord M12\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\"MILK\"]\n",
    "nielsen['upc_price'] = nielsen.price_per_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hey = nielsen.groupby('product_group_descr').count()\n",
    "categories = hey[hey.is_walmart<25000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"FRESH PRODUCE\",\n",
    "    \"BREAD AND BAKED GOODS\",\n",
    "    \"MILK\",\n",
    "    \"SNACKS\",\n",
    "    \"PACKAGED MEATS-DELI\",\n",
    "    \"CHEESE\",\n",
    "    \"UNPREP MEAT/POULTRY/SEAFOOD-FRZN\",\n",
    "    \"CARBONATED BEVERAGES\",\n",
    "    \"CONDIMENTS, GRAVIES, AND SAUCES\",\n",
    "    \"CANDY\",\n",
    "    \"JUICE, DRINKS - CANNED, BOTTLED\",\n",
    "    \"EGGS\",\n",
    "    \"CEREAL\",\n",
    "    \"PASTA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =[\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"PACKAGED MILK AND MODIFIERS\",\n",
    "    \"SPICES, SEASONING, EXTRACTS\",\n",
    "    \"SUGAR, SWEETENERS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\n",
    "    \"BAKING MIXES\",\n",
    "    \"MILK\",\n",
    "    \"CHEESE\",\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"CRACKERS\"\n",
    "    \"CANDY\",\n",
    "    \"PASTA\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()\n",
    "\n",
    "categories = ['_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMIER MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Prices_{i, t} = \\alpha + \\beta treat_i + \\gamma treat_i* post_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.012243573513392336\n",
      "Coef/err : 3.053990985459992\n",
      "CI_up : 0.0043688770208243355\n",
      "CI_down : 0.020180011111512908\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.purchase_year > treatment.Opening_date.dt.year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction']]\n",
    "    df = df[df.upc_price != 0]\n",
    "    reg0 = smf.ols(formula='np.log(upc_price) ~ treat + interaction', data=df)\n",
    "    results0 = reg0.fit()\n",
    "    #if abs(results0.params[2] / results0.bse[2]) > 2. :\n",
    "    if True:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results0.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results0.params[2] / results0.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results0.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results0.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEUXIEME MODELE - monthly time fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.02223552240504789\n",
      "Coef/err : 1.4577683184459918\n",
      "CI_up : -0.0075483686655423154\n",
      "CI_down : 0.052913240579445686\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.Opening_date.dt.year > treatment.purchase_year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    if True :\n",
    "    #if  abs(results1.params[2] / results1.bse[2])> 2.:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TROISIEME MODELE - state effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "_\n",
      "Coef : 0.03341797594021911\n",
      "Coef/err : 2.3002084834970784\n",
      "CI_up : 0.004873365074778313\n",
      "CI_down : 0.06277343007982616\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) + C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if True:\n",
    "    #if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUATRIEME MODELE - state*time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1751.\n",
      "Size of the control group: 701.\n",
      "Size of the control group: 460.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "CANDY\n",
      "Coef : 0.058063436001930535\n",
      "Coef/err : 3.8703008634540486\n",
      "CI_up : 0.028246807350231995\n",
      "CI_down : 0.08874467355666482\n",
      "Size of the control group: 1753.\n",
      "Size of the control group: 974.\n",
      "Size of the control group: 660.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "MILK\n",
      "Coef : -0.04109512362255707\n",
      "Coef/err : 5.162073822958096\n",
      "CI_up : -0.05625330864197686\n",
      "CI_down : -0.025693472241679283\n",
      "Size of the control group: 1610.\n",
      "Size of the control group: 450.\n",
      "Size of the control group: 246.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "COFFEE\n",
      "Coef : 0.03699238687960982\n",
      "Coef/err : 2.9354635273784924\n",
      "CI_up : 0.012139500147311244\n",
      "CI_down : 0.0624555313667321\n",
      "Size of the control group: 1699.\n",
      "Size of the control group: 648.\n",
      "Size of the control group: 393.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "PAPER PRODUCTS\n",
      "Coef : 0.10578211515236746\n",
      "Coef/err : 6.0283033645176305\n",
      "CI_up : 0.07021153549074\n",
      "CI_down : 0.14253495280272444\n",
      "Size of the control group: 1613.\n",
      "Size of the control group: 569.\n",
      "Size of the control group: 389.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "YOGURT\n",
      "Coef : 0.06032904640608816\n",
      "Coef/err : 2.80193903855756\n",
      "CI_up : 0.01775344934561196\n",
      "CI_down : 0.10468570494684859\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in ['CANDY', 'MILK', 'COFFEE', 'PAPER PRODUCTS', 'YOGURT']:\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    #product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 2]\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
