{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitées.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "# We concentrate our study on the movements (entries & exits) during the fiscal years 2015 and 2016\n",
    "#movements = fandom[((fandom.Opening_date >= '2015-01-31') & (fandom.Opening_date <= '2017-01-31')) | ((fandom.Closing_date >= '2015-01-31') & (fandom.Closing_date <= '2017-01-31'))]\n",
    "# Correction des effets de bord M12\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories=[\"MILK\"]\n",
    "#nielsen['upc_price'] = nielsen.price_per_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hey = nielsen.groupby('product_group_descr').count()\n",
    "categories = hey[hey.is_walmart<25000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = [    \"FRESH PRODUCE\",\n",
    "    \"BREAD AND BAKED GOODS\",\n",
    "    \"MILK\",\n",
    "    \"SNACKS\",\n",
    "    \"PACKAGED MEATS-DELI\",\n",
    "    \"CHEESE\",\n",
    "    \"UNPREP MEAT/POULTRY/SEAFOOD-FRZN\",\n",
    "    \"CARBONATED BEVERAGES\",]\n",
    "b = [\n",
    "    \"CONDIMENTS, GRAVIES, AND SAUCES\",\n",
    "    \"CANDY\",\n",
    "    \"JUICE, DRINKS - CANNED, BOTTLED\",\n",
    "    \"EGGS\",\n",
    "    \"CEREAL\",\n",
    "    \"PASTA\",\n",
    "    \"PAPER PRODUCTS\",\n",
    "    \"SEAFOOD - CANNED\"]\n",
    "\n",
    "categories=[\"SEAFOOD - CANNED\",\n",
    "    \"BEER\",\n",
    "    \"BREAKFAST FOODS - FROZEN\",\n",
    "    \"COOKIES\",\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "   \"COUGH AND COLD REMEDIES\",\n",
    "    \"DEODORANT\",\n",
    "    \"DESSERTS/FRUITS/TOPPINGS-FROZEN\",\n",
    "  \"DISPOSABLE DIAPERS\",\n",
    "  \"DRESSINGS/SALADS/PREP FOODS-DELI\",\n",
    "  \"GRT CARDS/PARTY NEEDS/NOVELTIES\",\n",
    "    \"ICE CREAM, NOVELTIES\",\n",
    "  \"JAMS, JELLIES, SPREADS\",\n",
    "  \"PIZZA/SNACKS/HORS DOEUVRES-FRZN\",\n",
    "    \"PREPARED FOOD-DRY MIXES\",\n",
    "    \"PREPARED FOOD-READY-TO-SERVE\",\n",
    "    \"SPICES, SEASONINGS, EXTRACTS\",\n",
    "    \"VEGETABLES - CANNED\",\n",
    "    \"VEGETABLES-FROZEN\",\n",
    "    \"WRAPPING MATERIALS AND BAGS\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories =[\n",
    "#    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "#    \"PACKAGED MILK AND MODIFIERS\",\n",
    "#    \"SPICES, SEASONING, EXTRACTS\",\n",
    "#    \"SUGAR, SWEETENERS\"\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories=[\n",
    "#    \"BAKING MIXES\",\n",
    "#    \"MILK\",\n",
    "#    \"CHEESE\",\n",
    "#    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "#    \"CRACKERS\"\n",
    "#    \"CANDY\",\n",
    "##    \"PASTA\",\n",
    "    \n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()\n",
    "\n",
    "#categories = ['_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELE 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Prices_{i, t} = \\alpha + \\beta treat_i + \\gamma treat_i* post_t + e*post_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 122.\n",
      "Size of the control group: 96.\n",
      "Size of the control group: 0.\n",
      "Size of the control group: 316.\n",
      "Size of the control group: 320.\n",
      "Size of the control group: 99.\n",
      "=========================================================\n",
      "COUGH AND COLD REMEDIES 3\n",
      "Coef : 0.07538213685124129\n",
      "Coef/err : 2.0242452384356384\n",
      "=========================================================\n",
      "COUGH AND COLD REMEDIES 6\n",
      "Coef : 0.07866822311256882\n",
      "Coef/err : 2.0213570237055563\n",
      "=========================================================\n",
      "COUGH AND COLD REMEDIES 11\n",
      "Coef : 0.09181070618451104\n",
      "Coef/err : 2.306721418722176\n",
      "Size of the control group: 71.\n",
      "Size of the control group: 93.\n",
      "Size of the control group: 4.\n",
      "Size of the control group: 492.\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 1\n",
      "Coef : 0.03466521897944608\n",
      "Coef/err : 2.759534672183056\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 3\n",
      "Coef : 0.03907663846238196\n",
      "Coef/err : 2.955295927463363\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 4\n",
      "Coef : 0.03409199776328875\n",
      "Coef/err : 2.7239999172316582\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 5\n",
      "Coef : 0.03518758821434176\n",
      "Coef/err : 2.7871911650909498\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 6\n",
      "Coef : 0.03369648114276291\n",
      "Coef/err : 2.6289574848421937\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 7\n",
      "Coef : 0.032552643693809724\n",
      "Coef/err : 2.4419447432394126\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 8\n",
      "Coef : 0.033359352540150544\n",
      "Coef/err : 2.6534024155991034\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 9\n",
      "Coef : 0.03300250079108635\n",
      "Coef/err : 2.619685845027355\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 10\n",
      "Coef : 0.035474511270329634\n",
      "Coef/err : 2.810248919701369\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 11\n",
      "Coef : 0.033453790248780146\n",
      "Coef/err : 2.664751479022158\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 13\n",
      "Coef : 0.031142970983375484\n",
      "Coef/err : 2.4218477381195034\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 15\n",
      "Coef : 0.0362391506900277\n",
      "Coef/err : 2.864289195734082\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 16\n",
      "Coef : 0.03394880465279604\n",
      "Coef/err : 2.7133253378293998\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 17\n",
      "Coef : 0.03423466221666227\n",
      "Coef/err : 2.7205192863458025\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 18\n",
      "Coef : 0.03458963536972348\n",
      "Coef/err : 2.7652442672943884\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 19\n",
      "Coef : 0.030171188536164184\n",
      "Coef/err : 2.385527517352367\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 20\n",
      "Coef : 0.03495061474923422\n",
      "Coef/err : 2.7964610422856\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 22\n",
      "Coef : 0.0342380983489452\n",
      "Coef/err : 2.721307074057802\n",
      "=========================================================\n",
      "DRESSINGS/SALADS/PREP FOODS-DELI 23\n",
      "Coef : 0.038486537890426664\n",
      "Coef/err : 3.030925912778669\n",
      "Size of the control group: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\base\\model.py:1512: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\base\\model.py:1512: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1671: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\anaconda\\envs\\tr_econ\\lib\\site-packages\\statsmodels\\base\\model.py:1512: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 334.\n",
      "=========================================================\n",
      "ICE CREAM, NOVELTIES 15\n",
      "Coef : -0.02278590174839501\n",
      "Coef/err : 2.4226508103497393\n",
      "Size of the control group: 205.\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 1\n",
      "Coef : 0.04656582924028685\n",
      "Coef/err : 2.6661975578712624\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 4\n",
      "Coef : 0.04877163024326747\n",
      "Coef/err : 2.548746183582311\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 5\n",
      "Coef : 0.052336808750176544\n",
      "Coef/err : 2.988774350883568\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 6\n",
      "Coef : 0.04098575309190888\n",
      "Coef/err : 2.33511963694018\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 7\n",
      "Coef : 0.04879343761317134\n",
      "Coef/err : 2.854449022707696\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 8\n",
      "Coef : 0.04852921182915981\n",
      "Coef/err : 2.823506245931434\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 9\n",
      "Coef : 0.040350372368320286\n",
      "Coef/err : 2.278583594458927\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 10\n",
      "Coef : 0.05451523926322688\n",
      "Coef/err : 3.0039777183876817\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 11\n",
      "Coef : 0.05067424057519254\n",
      "Coef/err : 2.8460748627952053\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 13\n",
      "Coef : 0.0531957733717896\n",
      "Coef/err : 3.0493408125083525\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 15\n",
      "Coef : 0.04514035033929087\n",
      "Coef/err : 2.593888793102275\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 16\n",
      "Coef : 0.05358123745194865\n",
      "Coef/err : 3.0182475544172775\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 17\n",
      "Coef : 0.04868219580439592\n",
      "Coef/err : 2.6656398410200923\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 18\n",
      "Coef : 0.05135109597618914\n",
      "Coef/err : 2.921714557648323\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 19\n",
      "Coef : 0.04657785782857804\n",
      "Coef/err : 2.594832709951585\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 20\n",
      "Coef : 0.046358216965187715\n",
      "Coef/err : 2.682752172844892\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 22\n",
      "Coef : 0.04622705104218161\n",
      "Coef/err : 2.5191260396115585\n",
      "=========================================================\n",
      "JAMS, JELLIES, SPREADS 23\n",
      "Coef : 0.04701306367471503\n",
      "Coef/err : 2.68043302036431\n",
      "Size of the control group: 0.\n",
      "Size of the control group: 338.\n",
      "Size of the control group: 269.\n",
      "Size of the control group: 0.\n",
      "Size of the control group: 372.\n",
      "Size of the control group: 357.\n",
      "=========================================================\n",
      "VEGETABLES-FROZEN 13\n",
      "Coef : -0.023782187570335678\n",
      "Coef/err : 2.1336489409878143\n",
      "=========================================================\n",
      "VEGETABLES-FROZEN 15\n",
      "Coef : -0.024549998587561905\n",
      "Coef/err : 2.1510102569501637\n",
      "=========================================================\n",
      "VEGETABLES-FROZEN 16\n",
      "Coef : -0.023600399039077624\n",
      "Coef/err : 2.05589257094704\n",
      "Size of the control group: 177.\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "    \n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.purchase_year > treatment.Opening_date.dt.year)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "    \n",
    "    \n",
    "\n",
    "    for month in [1, 3, 4, 5, 6, 7, 8, 9 , 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23]: #for month where at least one entry\n",
    "        # We keep only treated counties where the opening happened in month\n",
    "        treatment2 = treatment[treatment.opening_0 == month]\n",
    "\n",
    "        if (len(treatment2.guessed_store_county_fips.unique()) > 0) :\n",
    "\n",
    "            # Final dataset for the regression :\n",
    "            df = pd.concat((control, treatment2))[['upc_price', 'treat', 'purchase_month', 'purchase_year', 'time_effects', 'store_state']]\n",
    "            df = df[df.upc_price != 0]\n",
    "            df['purchase_0'] = df.purchase_month + 12 * (df.purchase_year - 2015)\n",
    "            df['post']=(df['purchase_0']>=month)\n",
    "            reg0 = smf.ols(formula='np.log(upc_price) ~ treat*post + C(time_effects) + C(store_state)', data=df)\n",
    "            results0 = reg0.fit()\n",
    "            if abs(results0.params[3] / results0.bse[3]) > 2. :\n",
    "            #if True:\n",
    "                print(\"=========================================================\")\n",
    "                print(category, month)\n",
    "                #print(results0.params)\n",
    "                print(f\"Coef : {np.exp(results0.params[3])-1}\")\n",
    "                print(f\"Coef/err : {abs(results0.params[3] / results0.bse[3])}\")\n",
    "                #print(f\"CI_up : {np.exp(results0.conf_int(alpha=0.05)[0][3])-1}\")\n",
    "                #print(f\"CI_down : {np.exp(results0.conf_int(alpha=0.05)[1][3])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMIER MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Prices_{i, t} = \\alpha + \\beta treat_i + \\gamma treat_i* post_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.012243573513392336\n",
      "Coef/err : 3.053990985459992\n",
      "CI_up : 0.0043688770208243355\n",
      "CI_down : 0.020180011111512908\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.purchase_year > treatment.Opening_date.dt.year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction']]\n",
    "    df = df[df.upc_price != 0]\n",
    "    reg0 = smf.ols(formula='np.log(upc_price) ~ treat + interaction', data=df)\n",
    "    results0 = reg0.fit()\n",
    "    #if abs(results0.params[2] / results0.bse[2]) > 2. :\n",
    "    if True:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results0.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results0.params[2] / results0.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results0.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results0.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEUXIEME MODELE - monthly time fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.02223552240504789\n",
      "Coef/err : 1.4577683184459918\n",
      "CI_up : -0.0075483686655423154\n",
      "CI_down : 0.052913240579445686\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.Opening_date.dt.year > treatment.purchase_year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    if True :\n",
    "    #if  abs(results1.params[2] / results1.bse[2])> 2.:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TROISIEME MODELE - state effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "_\n",
      "Coef : 0.03341797594021911\n",
      "Coef/err : 2.3002084834970784\n",
      "CI_up : 0.004873365074778313\n",
      "CI_down : 0.06277343007982616\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) + C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if True:\n",
    "    #if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUATRIEME MODELE - state*time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1751.\n",
      "Size of the control group: 701.\n",
      "Size of the control group: 460.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "CANDY\n",
      "Coef : 0.058063436001930535\n",
      "Coef/err : 3.8703008634540486\n",
      "CI_up : 0.028246807350231995\n",
      "CI_down : 0.08874467355666482\n",
      "Size of the control group: 1753.\n",
      "Size of the control group: 974.\n",
      "Size of the control group: 660.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "MILK\n",
      "Coef : -0.04109512362255707\n",
      "Coef/err : 5.162073822958096\n",
      "CI_up : -0.05625330864197686\n",
      "CI_down : -0.025693472241679283\n",
      "Size of the control group: 1610.\n",
      "Size of the control group: 450.\n",
      "Size of the control group: 246.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "COFFEE\n",
      "Coef : 0.03699238687960982\n",
      "Coef/err : 2.9354635273784924\n",
      "CI_up : 0.012139500147311244\n",
      "CI_down : 0.0624555313667321\n",
      "Size of the control group: 1699.\n",
      "Size of the control group: 648.\n",
      "Size of the control group: 393.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "PAPER PRODUCTS\n",
      "Coef : 0.10578211515236746\n",
      "Coef/err : 6.0283033645176305\n",
      "CI_up : 0.07021153549074\n",
      "CI_down : 0.14253495280272444\n",
      "Size of the control group: 1613.\n",
      "Size of the control group: 569.\n",
      "Size of the control group: 389.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "YOGURT\n",
      "Coef : 0.06032904640608816\n",
      "Coef/err : 2.80193903855756\n",
      "CI_up : 0.01775344934561196\n",
      "CI_down : 0.10468570494684859\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in ['CANDY', 'MILK', 'COFFEE', 'PAPER PRODUCTS', 'YOGURT']:\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    #product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 2]\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
