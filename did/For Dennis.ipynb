{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f28698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c745faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40823604",
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016\n",
    "\n",
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]\n",
    "\n",
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitées.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9d7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesn\\AppData\\Local\\Temp\\ipykernel_2688\\1154196187.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1390.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "Post-t coef : 0.05181727564731764\n",
      "Coef/err : 3.0254155812853054\n",
      "CI_up : 0.01794926244929229\n",
      "CI_down : 0.08681210563306951\n",
      "p_value : 0.0024848156425117287\n",
      "nobs : 34263.0\n",
      "R squared : 0.15575449526156848\n"
     ]
    }
   ],
   "source": [
    "#For each county and each month we take the mean of the prices of all categories\n",
    "pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n",
    "product_group = pool\n",
    "\n",
    "# The control group is composed of all states where nothing (no entry nor exit) happened.\n",
    "control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "# We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "# The treatment group is composed of the states where one entry took place in 2016 and where this entry is the only movement\n",
    "count = movements.groupby('County_fips').count()\n",
    "count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "# We create our dummies for the regression\n",
    "control['treat'] = False\n",
    "control['interaction'] = False\n",
    "control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015)\n",
    "control['effects'] = list(zip(control.store_state, control.purchase_0))\n",
    "\n",
    "treatment['treat'] = True\n",
    "treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0\n",
    "treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0))\n",
    "\n",
    "#we take only months before 5 months before the entry and months after 5 months after the entry\n",
    "treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 6]\n",
    "\n",
    "#if the treatment group is not empty\n",
    "if treatment.shape[0]>0 :\n",
    "    \n",
    "    # Final dataset for the regression :\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    if True :\n",
    "    #abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Post-t coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if True :\n",
    "    #abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")\n",
    "        print(f\"p_value : {results1.pvalues[2]}\")\n",
    "        print(f\"nobs : {results1.nobs}\")\n",
    "        print(f\"R squared : {results1.rsquared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fdbaef",
   "metadata": {},
   "source": [
    "### Parallel trend test : pre-treatment interaction dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f1fd6",
   "metadata": {},
   "source": [
    "#### On pooled dataset (all categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce883a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eea64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016\n",
    "\n",
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]\n",
    "\n",
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitées.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e00ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesn\\AppData\\Local\\Temp\\ipykernel_2688\\1552359494.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1390.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "Post-t coef : 0.026605341786368975\n",
      "Coef/err : 1.2084541040099148\n",
      "CI_up : -0.01619791476910415\n",
      "CI_down : 0.07127088222928069\n",
      "p_value : 0.22688124263607964\n",
      "nobs : 34263.0\n",
      "R squared : 0.15583189018149124\n",
      "Pre-t coef : -0.038607818970261554\n",
      "Coef/err : 1.7450540584628422\n",
      "CI_up : -0.08019743826145986\n",
      "CI_down : 0.004862308709081997\n",
      "p_value : 0.08098470726973861\n"
     ]
    }
   ],
   "source": [
    "#For each county and each month we take the mean of the prices of all categories\n",
    "pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n",
    "product_group = pool\n",
    "\n",
    "# The control group is composed of all states where nothing (no entry nor exit) happened.\n",
    "control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "# We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "# The treatment group is composed of the states where one entry took place in 2016 and where this entry is the only movement\n",
    "count = movements.groupby('County_fips').count()\n",
    "count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "# We create our dummies for the regression\n",
    "control['treat'] = False\n",
    "control['interaction'] = False\n",
    "control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015)\n",
    "control['effects'] = list(zip(control.store_state, control.purchase_0))\n",
    "control['p_interaction'] = False\n",
    "\n",
    "treatment['treat'] = True\n",
    "treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0\n",
    "treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0))\n",
    "#we add a pre-treatment interaction\n",
    "treatment['p_interaction'] = treatment.purchase_0 < (treatment.opening_0 - 9)\n",
    "\n",
    "#we take only months before 5 months before the entry and months after 5 months after the entry\n",
    "treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 6]\n",
    "\n",
    "#if the treatment group is not empty\n",
    "if treatment.shape[0]>0 :\n",
    "    \n",
    "    # Final dataset for the regression :\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects', \"p_interaction\"]]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + p_interaction + C(effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    if True :\n",
    "    #abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Post-t coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if True :\n",
    "    #abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")\n",
    "        print(f\"p_value : {results1.pvalues[2]}\")\n",
    "        print(f\"nobs : {results1.nobs}\")\n",
    "        print(f\"R squared : {results1.rsquared}\")\n",
    "        print(f\"Pre-t coef : {np.exp(results1.params[3])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[3] / results1.bse[3])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][3])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][3])-1}\")\n",
    "        print(f\"p_value : {results1.pvalues[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2deb13",
   "metadata": {},
   "source": [
    "### Parallel trend test : placebo treatment group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092b201",
   "metadata": {},
   "source": [
    "#### On pooled dataset (all categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feaec10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from random import choice\n",
    "\n",
    "\n",
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016\n",
    "\n",
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]\n",
    "\n",
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitées.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc3d53f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesn\\AppData\\Local\\Temp\\ipykernel_33996\\962717880.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1390.\n",
      "Size of the treatment group: 65.\n",
      "remaining_c_county_list len : 1326\n",
      "=========================================================\n",
      "Interaction Coef : 0.05682741600373542\n",
      "Coef/err : 3.308891076225717\n",
      "CI_up : 0.022786846981806885\n",
      "CI_down : 0.0920009291408097\n",
      "p_value : 0.0009377071200183043\n",
      "nobs : 32705.0\n",
      "R squared : 0.15359030055551126\n"
     ]
    }
   ],
   "source": [
    "#For each county and each month we take the mean of the prices of all categories\n",
    "pool = nielsen.groupby(['store_state','guessed_store_county','guessed_store_county_fips','purchase_month','purchase_year']).mean().reset_index()\n",
    "product_group = pool\n",
    "\n",
    "# The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "# We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "# The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "count = movements.groupby('County_fips').count()\n",
    "count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "#if the treatment group is not empty\n",
    "if treatment.shape[0] > 0 : \n",
    "\n",
    "    ### Creation of the placebo treatment group\n",
    "\n",
    "        #We create an 'Opening_date' column for the control group (because we have to add an Opening_date to the\n",
    "    #placebo treatment group counties)\n",
    "\n",
    "    control['Opening_date']=0\n",
    "\n",
    "    #We gather relevant information on the actual treatment group in an array\n",
    "\n",
    "    treatment_info = treatment.groupby(['guessed_store_county_fips','store_state','Opening_date']).nunique()['is_walmart'].reset_index().to_numpy()\n",
    "\n",
    "\n",
    "    #We select our placebo treatment group counties\n",
    "\n",
    "    new_t_county_fips_list = []\n",
    "    # error will be True if we can't find counties in the control group to be used as placebo treatment group counties\n",
    "    error = False\n",
    "    #total nb of counties we want in the placebo treatment group\n",
    "    nb_of_t_counties = treatment_info.shape[0]\n",
    "    #list of indexes in treatment_info of the actual Tg counties for which we could not find a placebo in the same state\n",
    "    index_of_missing_counties = []\n",
    "    for k in range(nb_of_t_counties): \n",
    "        #for each actual Tg county, we find a placebo replacement\n",
    "        #we get the county state\n",
    "        state = treatment_info[k][1]\n",
    "        #we get the county opening date\n",
    "        opening_date = treatment_info[k][2]\n",
    "        #list of the candidate county_fips for our placebo (same state as the actual Tg county, not the same county as another already existing placebo county)\n",
    "        c_county_list = control[(control.store_state == state)&(~np.isin(control.guessed_store_county_fips, new_t_county_fips_list))].guessed_store_county_fips.unique().copy().tolist() \n",
    "        nb_of_c_counties = len(c_county_list) #nb of candidates\n",
    "        if nb_of_c_counties > 0 :\n",
    "            new_t_county_fips = choice(c_county_list) #random choice of one candidate\n",
    "            new_t_county_fips_list.append(new_t_county_fips)\n",
    "            #we add the right opening_date to placebo county\n",
    "            control.loc[control.guessed_store_county_fips==new_t_county_fips, 'Opening_date'] = opening_date \n",
    "        else : \n",
    "            #if we did not find suitable candidates in the right state\n",
    "            index_of_missing_counties.append(k)\n",
    "\n",
    "    nb_of_missing_counties = len(index_of_missing_counties)\n",
    "    if nb_of_missing_counties != 0 : \n",
    "        #if we did not find suitable candidates in the right state for at least one state, we search candidates whatever the state\n",
    "        for k in index_of_missing_counties:\n",
    "            remaining_c_county_list = control[~np.isin(control.guessed_store_county_fips, new_t_county_fips_list)].guessed_store_county_fips.unique().copy().tolist()\n",
    "            print(f'remaining_c_county_list len : {len(remaining_c_county_list)}')\n",
    "            if len(remaining_c_county_list) <= 0 :\n",
    "                error = True\n",
    "            else :\n",
    "                new_t_county_fips = choice(remaining_c_county_list)\n",
    "                new_t_county_fips_list.append(new_t_county_fips)\n",
    "                control.loc[control.guessed_store_county_fips==new_t_county_fips, 'Opening_date'] = opening_date\n",
    "    if not error :\n",
    "\n",
    "        #we keep in our placebo Tg only the selected placebo counties\n",
    "        new_treatment = control[np.isin(control.guessed_store_county_fips, new_t_county_fips_list)].copy()\n",
    "        new_control = control[~np.isin(control.guessed_store_county_fips, new_t_county_fips_list)].copy()\n",
    "\n",
    "        ### End of the creation of the placebo treatment group\n",
    "\n",
    "        \n",
    "        \n",
    "        # We create our dummies for the regression\n",
    "        new_control['treat'] = False\n",
    "        new_control['interaction'] = False\n",
    "        new_control['purchase_0'] = new_control.purchase_month + 12 * (new_control.purchase_year - 2015)\n",
    "        new_control['effects'] = list(zip(new_control.store_state, new_control.purchase_0))\n",
    "\n",
    "        new_treatment['treat'] = True\n",
    "        new_treatment['purchase_0'] = new_treatment.purchase_month + 12 * (new_treatment.purchase_year - 2015)\n",
    "        new_treatment['opening_0'] = pd.DatetimeIndex(new_treatment.Opening_date).month  + 12 * (pd.DatetimeIndex(new_treatment.Opening_date).year - 2015)\n",
    "        new_treatment['interaction'] = new_treatment.purchase_0 >= new_treatment.opening_0\n",
    "        new_treatment['effects'] = list(zip(new_treatment.store_state, new_treatment.purchase_0))\n",
    "\n",
    "        new_treatment = new_treatment[abs(new_treatment.purchase_0-new_treatment.opening_0) >= 6]\n",
    "\n",
    "        #if the treatment group is not empty\n",
    "        if new_treatment.shape[0]>0 :\n",
    "            \n",
    "            # Final dataset for the regression :\n",
    "\n",
    "            df = pd.concat((new_control, new_treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "            df = df[df.upc_price != 0]\n",
    "\n",
    "            reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "            results1 = reg1.fit()\n",
    "            print(\"=========================================================\")\n",
    "            if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "                print(f\"Interaction Coef : {np.exp(results1.params[2])-1}\")\n",
    "            print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "            print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "            print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")\n",
    "            print(f\"p_value : {results1.pvalues[2]}\")\n",
    "            print(f\"nobs : {results1.nobs}\")\n",
    "            print(f\"R squared : {results1.rsquared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddb4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
