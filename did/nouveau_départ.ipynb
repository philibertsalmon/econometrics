{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen15['year'] = 2015\n",
    "nielsen16['year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nielsen = pd.concat((nielsen15, nielsen16))\n",
    "nielsen = nielsen[~nielsen.is_walmart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entriy/exit dates\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitÃ©es.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# We drop the state in which we do not trust our data (some mistakes stillremain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "# We concentrate our study on the movements (entries & exits) during the fiscal years 2015 and 2016\n",
    "#movements = fandom[((fandom.Opening_date >= '2015-01-31') & (fandom.Opening_date <= '2017-01-31')) | ((fandom.Closing_date >= '2015-01-31') & (fandom.Closing_date <= '2017-01-31'))]\n",
    "# Correction des effets de bord M12\n",
    "movements = fandom[((fandom.Opening_date >= '2014-01-31') & (fandom.Opening_date <= '2018-01-31')) | ((fandom.Closing_date >= '2014-01-31') & (fandom.Closing_date <= '2018-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\"MILK\"]\n",
    "nielsen['upc_price'] = nielsen.price_per_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hey = nielsen.groupby('product_group_descr').count()\n",
    "categories = hey[hey.is_walmart>=25000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"FRESH PRODUCE\",\n",
    "    \"BREAD AND BAKED GOODS\",\n",
    "    \"MILK\",\n",
    "    \"SNACKS\",\n",
    "    \"PACKAGED MEATS-DELI\",\n",
    "    \"CHEESE\",\n",
    "    \"UNPREP MEAT/POULTRY/SEAFOOD-FRZN\",\n",
    "    \"CARBONATED BEVERAGES\",\n",
    "    \"CONDIMENTS, GRAVIES, AND SAUCES\",\n",
    "    \"CANDY\",\n",
    "    \"JUICE, DRINKS - CANNED, BOTTLED\",\n",
    "    \"EGGS\",\n",
    "    \"CEREAL\",\n",
    "    \"PASTA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =[\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"PACKAGED MILK AND MODIFIERS\",\n",
    "    \"SPICES, SEASONING, EXTRACTS\",\n",
    "    \"SUGAR, SWEETENERS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=[\n",
    "    \"BAKING MIXES\",\n",
    "    \"MILK\",\n",
    "    \"CHEESE\",\n",
    "    \"COT CHEESE, SOUR CREAM, TOPPINGS\",\n",
    "    \"CRACKERS\"\n",
    "    \"CANDY\",\n",
    "    \"PASTA\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()\n",
    "\n",
    "categories = ['_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUTOMOTIVE', 'BABY FOOD', 'BABY NEEDS', 'BAKED GOODS-FROZEN',\n",
       "       'BAKING MIXES', 'BAKING SUPPLIES', 'BATTERIES AND FLASHLIGHTS',\n",
       "       'BEER', 'BOOKS AND MAGAZINES', 'BREAD AND BAKED GOODS',\n",
       "       'BREAKFAST FOOD', 'BREAKFAST FOODS-FROZEN', 'BUTTER AND MARGARINE',\n",
       "       'CANDY', 'CANNING, FREEZING SUPPLIES', 'CARBONATED BEVERAGES',\n",
       "       'CEREAL', 'CHARCOAL, LOGS, ACCESSORIES', 'CHEESE', 'COFFEE',\n",
       "       'CONDIMENTS, GRAVIES, AND SAUCES', 'COOKIES', 'COOKWARE',\n",
       "       'COSMETICS', 'COT CHEESE, SOUR CREAM, TOPPINGS',\n",
       "       'COUGH AND COLD REMEDIES', 'CRACKERS', 'DEODORANT',\n",
       "       'DESSERTS, GELATINS, SYRUP', 'DESSERTS/FRUITS/TOPPINGS-FROZEN',\n",
       "       'DETERGENTS', 'DIET AIDS', 'DISPOSABLE DIAPERS', 'DOUGH PRODUCTS',\n",
       "       'DRESSINGS/SALADS/PREP FOODS-DELI', 'EGGS',\n",
       "       'ELECTRONICS, RECORDS, TAPES', 'ETHNIC HABA', 'FEMININE HYGIENE',\n",
       "       'FIRST AID', 'FLORAL, GARDENING', 'FLOUR', 'FRAGRANCES - WOMEN',\n",
       "       'FRESH MEAT', 'FRESH PRODUCE', 'FRESHENERS AND DEODORIZERS',\n",
       "       'FRUIT - CANNED', 'FRUIT - DRIED', 'GLASSWARE, TABLEWARE',\n",
       "       'GROOMING AIDS', 'GRT CARDS/PARTY NEEDS/NOVELTIES', 'GUM',\n",
       "       'HAIR CARE', 'HARDWARE, TOOLS', 'HOUSEHOLD CLEANERS',\n",
       "       'HOUSEHOLD SUPPLIES', 'HOUSEWARES, APPLIANCES', 'ICE',\n",
       "       'ICE CREAM, NOVELTIES', 'INSECTICDS/PESTICDS/RODENTICDS',\n",
       "       'JAMS, JELLIES, SPREADS', 'JUICE, DRINKS - CANNED, BOTTLED',\n",
       "       'JUICES, DRINKS-FROZEN', 'KITCHEN GADGETS', 'LAUNDRY SUPPLIES',\n",
       "       'LIGHT BULBS, ELECTRIC GOODS', 'LIQUOR', 'MAGNET DATA',\n",
       "       'MEDICATIONS/REMEDIES/HEALTH AIDS', \"MEN'S TOILETRIES\", 'MILK',\n",
       "       'NUTS', 'ORAL HYGIENE', 'PACKAGED MEATS-DELI',\n",
       "       'PACKAGED MILK AND MODIFIERS', 'PAPER PRODUCTS', 'PASTA',\n",
       "       'PERSONAL SOAP AND BATH ADDITIVES', 'PET CARE', 'PET FOOD',\n",
       "       'PHOTOGRAPHIC SUPPLIES', 'PICKLES, OLIVES, AND RELISH',\n",
       "       'PIZZA/SNACKS/HORS DOEURVES-FRZN', 'PREPARED FOOD-DRY MIXES',\n",
       "       'PREPARED FOOD-READY-TO-SERVE', 'PREPARED FOODS-FROZEN',\n",
       "       'PUDDING, DESSERTS-DAIRY', 'SALAD DRESSINGS, MAYO, TOPPINGS',\n",
       "       'SANITARY PROTECTION', 'SEAFOOD - CANNED', 'SEASONAL',\n",
       "       'SEWING NOTIONS', 'SHAVING NEEDS', 'SHOE CARE', 'SHORTENING, OIL',\n",
       "       'SKIN CARE PREPARATIONS', 'SNACKS', 'SNACKS, SPREADS, DIPS-DAIRY',\n",
       "       'SOFT DRINKS-NON-CARBONATED', 'SOFT GOODS', 'SOUP',\n",
       "       'SPICES, SEASONING, EXTRACTS', 'STATIONERY, SCHOOL SUPPLIES',\n",
       "       'SUGAR, SWEETENERS', 'TABLE SYRUPS, MOLASSES', 'TEA',\n",
       "       'TOBACCO & ACCESSORIES', 'TOYS & SPORTING GOODS',\n",
       "       'UNGROUPED ITEMS', 'UNPREP MEAT/POULTRY/SEAFOOD-FRZN',\n",
       "       'VEGETABLES - CANNED', 'VEGETABLES AND GRAINS - DRIED',\n",
       "       'VEGETABLES-FROZEN', 'VITAMINS', 'WINE',\n",
       "       'WRAPPING MATERIALS AND BAGS', 'YEAST', 'YOGURT'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = nielsen.product_group_descr.unique()\n",
    "categories.sort()\n",
    "haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREMIER MODELE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Prices_{i, t} = \\alpha + \\beta treat_i + \\gamma treat_i* post_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.012243573513392336\n",
      "Coef/err : 3.053990985459992\n",
      "CI_up : 0.0043688770208243355\n",
      "CI_down : 0.020180011111512908\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.purchase_year > treatment.Opening_date.dt.year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction']]\n",
    "    df = df[df.upc_price != 0]\n",
    "    reg0 = smf.ols(formula='np.log(upc_price) ~ treat + interaction', data=df)\n",
    "    results0 = reg0.fit()\n",
    "    #if abs(results0.params[2] / results0.bse[2]) > 2. :\n",
    "    if True:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results0.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results0.params[2] / results0.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results0.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results0.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEUXIEME MODELE - monthly time fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.02223552240504789\n",
      "Coef/err : 1.4577683184459918\n",
      "CI_up : -0.0075483686655423154\n",
      "CI_down : 0.052913240579445686\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    #treatment['interaction'] = ((treatment.Opening_date.dt.year == treatment.purchase_year) & (treatment.Opening_date.dt.month > treatment.purchase_month)) | (treatment.Opening_date.dt.year > treatment.purchase_year)\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    if True :\n",
    "    #if  abs(results1.params[2] / results1.bse[2])> 2.:\n",
    "        print(\"=========================================================\")\n",
    "        print(category)\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TROISIEME MODELE - state effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "_\n",
      "Coef : 0.03341797594021911\n",
      "Coef/err : 2.3002084834970784\n",
      "CI_up : 0.004873365074778313\n",
      "CI_down : 0.06277343007982616\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) + C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if True:\n",
    "    #if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUATRIEME MODELE - state*time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel sâest bloquÃ© lors de lâexÃ©cution du code dans la cellule active ou une cellule prÃ©cÃ©dente. Veuillez vÃ©rifier le code dans la ou les cellules pour identifier une cause possible de lâÃ©chec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus dâinformations. Pour plus dâinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    #product_group = pool\n",
    "    product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    #print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    #print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 + post\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'store_state', 'time_effects']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "\n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects) * C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "        print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['BEER', 'BREAKFAST FOODS-FROZEN', 'CANDY', 'CONDIMENTS, GRAVIES, AND SAUCES', 'COOKIES', 'COT CHEESE, SOUR CREAM, TOPPINGS', 'COUGH AND COLD REMEDIES', 'DEODORANT', 'DESSERTS, GELATINS, SYRUP', 'DESSERTS/FRUITS/TOPPINGS-FROZEN', 'DISPOSABLE DIAPERS', 'DRESSINGS/SALADS/PREP FOODS-DELI', 'GRT CARDS/PARTY NEEDS/NOVELTIES', 'ICE CREAM, NOVELTIES', 'JAMS, JELLIES, SPREADS', 'JUICE, DRINKS - CANNED, BOTTLED', 'MILK', 'PAPER PRODUCTS', 'PIZZA/SNACKS/HORS DOEURVES-FRZN', 'PREPARED FOOD-DRY MIXES', 'PREPARED FOOD-READY-TO-SERVE', 'SEAFOOD - CANNED', 'SPICES, SEASONING, EXTRACTS', 'SNACKS', 'UNPREP MEAT/POULTRY/SEAFOOD-FRZN', 'VEGETABLES - CANNED', 'VEGETABLES-FROZEN', 'WRAPPING MATERIALS AND BAGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the control group: 1802.\n",
      "Size of the control group: 1390.\n",
      "Size of the control group: 1390.\n",
      "Size of the treatment group: 65.\n",
      "=========================================================\n",
      "_\n",
      "Coef : 0.0617044241469038\n",
      "Coef/err : 3.1800678315193025\n"
     ]
    }
   ],
   "source": [
    "# We choose to focus on milk prices\n",
    "for category in categories:\n",
    "    #product_group = nielsen[nielsen.product_group_descr == category]\n",
    "    product_group = pool\n",
    "    #product_group = nielsen\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    #nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    #control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))]\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # We create our dummies for the regression\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['time_effects'] = list(zip(control.purchase_year, control.purchase_month))\n",
    "    control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015)\n",
    "    #control['effects'] = list(zip(control.store_state, control.purchase_0))\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015)\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0\n",
    "    #treatment['interaction'] = treatment.purchase_0 - treatment.opening_0\n",
    "    treatment['time_effects'] = list(zip(treatment.purchase_year, treatment.purchase_month))\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) >= 8]\n",
    "    #treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0))\n",
    "\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'time_effects', 'store_state']]\n",
    "    df = df[df.upc_price != 0]\n",
    "\n",
    "    \n",
    "    reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(time_effects)*C(store_state)', data=df)\n",
    "    results1 = reg1.fit()\n",
    "    print(\"=========================================================\")\n",
    "    print(category)\n",
    "    if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "        print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "    print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "    #if abs(results1.params[2] / results1.bse[2]) >= 2.:\n",
    "    #    print(f\"CI_up : {np.exp(results1.conf_int(alpha=0.05)[0][2])-1}\")\n",
    "    #    print(f\"CI_down : {np.exp(results1.conf_int(alpha=0.05)[1][2])-1}\")\n",
    "    #print(results1.summary())\n",
    "    \"\"\"\n",
    "\n",
    "    reg2 = smf.ols(formula = 'np.log(upc_price) ~ treat + C(interaction) + C(time_effects)', data=df)\n",
    "    results2 = reg2.fit()\n",
    "    print(results2.summary())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BAKED GOODS-FROZEN', 'BAKING MIXES', 'BAKING SUPPLIES',\n",
       "       'BREAD AND BAKED GOODS', 'BREAKFAST FOOD', 'BUTTER AND MARGARINE',\n",
       "       'CANDY', 'CARBONATED BEVERAGES', 'CEREAL', 'CHEESE', 'COFFEE',\n",
       "       'CONDIMENTS, GRAVIES, AND SAUCES', 'COOKIES',\n",
       "       'COT CHEESE, SOUR CREAM, TOPPINGS', 'CRACKERS',\n",
       "       'DESSERTS, GELATINS, SYRUP', 'DETERGENTS', 'DOUGH PRODUCTS',\n",
       "       'DRESSINGS/SALADS/PREP FOODS-DELI', 'EGGS', 'FRESH PRODUCE',\n",
       "       'FRUIT - CANNED', 'ICE CREAM, NOVELTIES', 'JAMS, JELLIES, SPREADS',\n",
       "       'JUICE, DRINKS - CANNED, BOTTLED', 'MEDICATIONS/REMEDIES/HEALTH AIDS',\n",
       "       'MILK', 'NUTS', 'PACKAGED MEATS-DELI', 'PACKAGED MILK AND MODIFIERS',\n",
       "       'PAPER PRODUCTS', 'PASTA', 'PET FOOD', 'PICKLES, OLIVES, AND RELISH',\n",
       "       'PIZZA/SNACKS/HORS DOEURVES-FRZN', 'PREPARED FOOD-DRY MIXES',\n",
       "       'PREPARED FOOD-READY-TO-SERVE', 'PREPARED FOODS-FROZEN',\n",
       "       'SALAD DRESSINGS, MAYO, TOPPINGS', 'SHORTENING, OIL', 'SNACKS',\n",
       "       'SOFT DRINKS-NON-CARBONATED', 'SOUP', 'SPICES, SEASONING, EXTRACTS',\n",
       "       'SUGAR, SWEETENERS', 'TEA', 'UNPREP MEAT/POULTRY/SEAFOOD-FRZN',\n",
       "       'VEGETABLES - CANNED', 'VEGETABLES-FROZEN',\n",
       "       'WRAPPING MATERIALS AND BAGS', 'YOGURT'],\n",
       "      dtype='object', name='product_group_descr')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef : 0.0617044241468927\n",
    "Coef/err : 3.1800678315187234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
