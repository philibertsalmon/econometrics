{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reression code\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change path\n",
    "nielsen15 = pd.read_csv('../../Nielsen/aggregated_nielsen_2015.csv')\n",
    "nielsen16 = pd.read_csv('../..//Nielsen/aggregated_nielsen_2016.csv')\n",
    "nielsen = pd.concat((nielsen15, nielsen16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Walmart concurents\n",
    "nielsen = nielsen[~nielsen.is_walmart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing entries/exits data\n",
    "# TODO change path\n",
    "fandom = pd.read_csv('../data_collection/plein_de_data/fandom_traitÃ©es.csv', parse_dates=['Opening_date', 'Closing_date'])[['State', 'County_name', 'County_fips', 'Opening_date', 'Closing_date']]\n",
    "\n",
    "# Droping the state in which we do not trust our data (some mistakes still,remain)\n",
    "fandom = fandom[~np.isin(fandom.State, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "nielsen = nielsen[~np.isin(nielsen.store_state, ('CA', 'GA', 'KS', 'LA', 'TX'))]\n",
    "\n",
    "# We concentrate our study on the movements (entries & exits) that happened between 2014 and 2017 (fiscal year). We add 2014 and 2017 to eliminate side effects.\n",
    "movements = fandom[((fandom.Opening_date >= '2015-01-31') & (fandom.Opening_date <= '2017-01-31')) | ((fandom.Closing_date >= '2015-01-31') & (fandom.Closing_date <= '2017-01-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the observations around the opening date (0, 1, 3, 5, 7, 9 , 11)\n",
    "dropping_period = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Pooled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the average price per category to have a first overview of the effect\n",
    "pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Pooled results\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 1457.\n",
      "Size of the treatment group: 91.\n",
      "Coef : 0.03628233615121923\n",
      "Coef/err : 2.2418082026301285\n"
     ]
    }
   ],
   "source": [
    "print(\"=========================================================\")\n",
    "print(\"ENTRY - Pooled results\")\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "product_group = pool\n",
    "\n",
    "\n",
    "# The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "# We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "# The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "count = movements.groupby('County_fips').count()\n",
    "count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))] # Treatment group composed by the entries\n",
    "\n",
    "treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "# Creating the dummies\n",
    "control['treat'] = False\n",
    "control['interaction'] = False\n",
    "control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015) # Creating one unique time variable\n",
    "control['effects'] = list(zip(control.store_state, control.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "treatment['treat'] = True\n",
    "treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015) # Creating one unique time variable\n",
    "treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 # The post dummy equals to one in the treatment group, after the opening month\n",
    "treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) > dropping_period]\n",
    "treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "\n",
    "\n",
    "# Final dataset for the regression :\n",
    "df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "df = df[df.upc_price != 0] # Dropping the errors in the set\n",
    "\n",
    "\n",
    "reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "results1 = reg1.fit()\n",
    "\n",
    "print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focusing on the categories with the highest number of observations\n",
    "categories_count = nielsen.groupby('product_group_descr').count()\n",
    "categories = categories_count[categories_count.is_walmart>=25000].index\n",
    "\n",
    "# It could be :\n",
    "# categories = nielsen.product_group_descr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "ENTRY - BAKED GOODS-FROZEN\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 118.\n",
      "Size of the treatment group: 89.\n",
      "Coef/err : 0.43005065876054466\n",
      "=========================================================\n",
      "ENTRY - BAKING MIXES\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 209.\n",
      "Size of the treatment group: 91.\n",
      "Coef/err : 1.1525473486290227\n",
      "=========================================================\n",
      "ENTRY - BAKING SUPPLIES\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 256.\n",
      "Size of the treatment group: 91.\n",
      "Coef/err : 1.4663504380069932\n",
      "=========================================================\n",
      "ENTRY - BREAD AND BAKED GOODS\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 833.\n",
      "Size of the treatment group: 91.\n",
      "Coef/err : 0.5137064845539167\n",
      "=========================================================\n",
      "ENTRY - BREAKFAST FOOD\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 269.\n",
      "Size of the treatment group: 91.\n",
      "Coef/err : 0.08379756453787691\n",
      "=========================================================\n",
      "ENTRY - BUTTER AND MARGARINE\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 325.\n",
      "Size of the treatment group: 91.\n",
      "Coef : 0.02555957645714102\n",
      "Coef/err : 2.1911672072843817\n",
      "=========================================================\n",
      "ENTRY - CANDY\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 508.\n",
      "Size of the treatment group: 91.\n",
      "Coef : 0.03418941652907859\n",
      "Coef/err : 2.3614258938985713\n",
      "=========================================================\n",
      "ENTRY - CARBONATED BEVERAGES\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 574.\n",
      "Size of the treatment group: 91.\n",
      "Coef/err : 1.5910047070247824\n",
      "=========================================================\n",
      "ENTRY - CEREAL\n",
      "---------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2x/jyk25dss11q4zcwpyjj6vtx40000gn/T/ipykernel_6354/2806014997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# The control group is composed by all states where nothing (no entry nor exit) happened.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguessed_store_county_fips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Keeping in the control group the only counties where we have data for the entire time period (24 months)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36misin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[1;32m    733\u001b[0m     \"\"\"\n\u001b[1;32m    734\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0m\u001b[1;32m    736\u001b[0m                 invert=invert).reshape(element.shape)\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36min1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"ENTRY - {category}\")\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "    # Keeping in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "\n",
    "    # Keeping in the control group the only counties where 4 observations per month and category at least\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Opening_date>='2015-01-31' ) & (treatment_movements.Opening_date<='2017-01-31') & ((treatment_movements.Closing_date>'2017-01-31') | (treatment_movements.Closing_date.apply(str) == 'NaT'))] # Treatment group composed by the entries\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Creating the dummies\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015) # Creating one unique time variable\n",
    "    control['effects'] = list(zip(control.store_state, control.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015) # Creating one unique time variable\n",
    "    treatment['opening_0'] = treatment.Opening_date.dt.month  + 12 * (treatment.Opening_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.opening_0 # The post dummy equals to one in the treatment group, after the opening month\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.opening_0) > dropping_period]\n",
    "    treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "    df = df[df.upc_price != 0] # Dropping the errors in the set\n",
    "\n",
    "    try:\n",
    "        reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "        results1 = reg1.fit()\n",
    "\n",
    "        if abs(results1.params[2] / results1.bse[2]) > 2.:\n",
    "            print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "\n",
    "    except:\n",
    "        print('Method does not converge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Pooled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the average price per category to have a first overview of the effect\n",
    "pool = pd.DataFrame(nielsen.groupby(['is_walmart', 'store_state', 'guessed_store_county', 'guessed_store_county_fips', 'purchase_year', 'purchase_month']).mean()['upc_price']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "ENTRY - Pooled results\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 1457.\n",
      "Size of the treatment group: 26.\n",
      "Coef : 0.036159872219974076\n",
      "Coef/err : 1.271974218395699\n"
     ]
    }
   ],
   "source": [
    "print(\"=========================================================\")\n",
    "print(\"EXIT - Pooled results\")\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "product_group = pool\n",
    "\n",
    "\n",
    "# The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "# We keep in the control group the only counties where we have data for the entire time period (24 months)\n",
    "nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "# The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "count = movements.groupby('County_fips').count()\n",
    "count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "treatment_movements = treatment_movements[(treatment_movements.Closing_date>='2015-01-31' ) & (treatment_movements.Closing_date<='2017-01-31') & (treatment_movements.Opening_date<'2015-01-31')] # Treatment group composed by the exits\n",
    "\n",
    "treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "# Creating the dummies\n",
    "control['treat'] = False\n",
    "control['interaction'] = False\n",
    "control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015) # Creating one unique time variable\n",
    "control['effects'] = list(zip(control.store_state, control.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "treatment['treat'] = True\n",
    "treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015) # Creating one unique time variable\n",
    "treatment['closing_0'] = treatment.Closing_date.dt.month  + 12 * (treatment.Closing_date.dt.year - 2015)\n",
    "treatment['interaction'] = treatment.purchase_0 >= treatment.closing_0 # The post dummy equals to one in the treatment group, after the closing month\n",
    "treatment = treatment[abs(treatment.purchase_0-treatment.closing_0) > dropping_period]\n",
    "treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "\n",
    "\n",
    "# Final dataset for the regression :\n",
    "df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "df = df[df.upc_price != 0] # Dropping the errors in the set\n",
    "\n",
    "\n",
    "reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "results1 = reg1.fit()\n",
    "\n",
    "print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focusing on the categories with the highest number of observations\n",
    "categories_count = nielsen.groupby('product_group_descr').count()\n",
    "categories = categories_count[categories_count.is_walmart>=25000].index\n",
    "\n",
    "# It could be :\n",
    "# categories = nielsen.product_group_descr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "EXIT - BAKED GOODS-FROZEN\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 118.\n",
      "Size of the treatment group: 42.\n",
      "Coef/err : 0.7022280341007358\n",
      "=========================================================\n",
      "EXIT - BAKING MIXES\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 209.\n",
      "Size of the treatment group: 42.\n",
      "Coef/err : 0.3759251908962499\n",
      "=========================================================\n",
      "EXIT - BAKING SUPPLIES\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 256.\n",
      "Size of the treatment group: 43.\n",
      "Coef/err : 0.031220037980654362\n",
      "=========================================================\n",
      "EXIT - BREAD AND BAKED GOODS\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 833.\n",
      "Size of the treatment group: 43.\n",
      "Method does not converge\n",
      "=========================================================\n",
      "EXIT - BREAKFAST FOOD\n",
      "---------------------------------------------------------\n",
      "Size of the control group: 269.\n",
      "Size of the treatment group: 38.\n",
      "Coef/err : 0.7639617207316075\n",
      "=========================================================\n",
      "EXIT - BUTTER AND MARGARINE\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"EXIT - {category}\")\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "    product_group = nielsen[nielsen.product_group_descr == category]\n",
    "\n",
    "\n",
    "    # The control group is composed by all states where nothing (no entry nor exit) happened.\n",
    "    control = product_group[~np.isin(product_group.guessed_store_county_fips, movements)].copy()\n",
    "\n",
    "    # Keeping in the control group the only counties where we have data for the entire time period (24 months)\n",
    "    nb_months = control.groupby('guessed_store_county_fips').count()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_months[nb_months.is_walmart==24].index)]\n",
    "\n",
    "    # Keeping in the control group the only counties where 4 observations per month and category at least\n",
    "    nb_obs = control.groupby('guessed_store_county_fips').min()\n",
    "    control = control[np.isin(control.guessed_store_county_fips, nb_obs[nb_obs.nb_of_obs > 3].index)]\n",
    "    print(f\"Size of the control group: {len(control.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "    # The treatment group is composed by the states where one entry took place in 2016 and where this entry is the only movement\n",
    "    count = movements.groupby('County_fips').count()\n",
    "    count = count[count.State == 1] # No more than one movement in the treatement group\n",
    "    treatment_movements = movements[(np.isin(movements.County_fips, count.index))]\n",
    "    treatment_movements = treatment_movements[(treatment_movements.Closing_date>='2015-01-31' ) & (treatment_movements.Closing_date<='2017-01-31') & ((treatment_movements.Opening_date<'2015-01-31'))] # Treatment group composed by the entries\n",
    "\n",
    "    treatment = product_group[np.isin(product_group.guessed_store_county_fips, treatment_movements.County_fips )].copy()\n",
    "    treatment = treatment.merge(treatment_movements, left_on='guessed_store_county_fips', right_on='County_fips')\n",
    "    print(f\"Size of the treatment group: {len(treatment.guessed_store_county_fips.unique())}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Creating the dummies\n",
    "    control['treat'] = False\n",
    "    control['interaction'] = False\n",
    "    control['purchase_0'] = control.purchase_month + 12 * (control.purchase_year - 2015) # Creating one unique time variable\n",
    "    control['effects'] = list(zip(control.store_state, control.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "    treatment['treat'] = True\n",
    "    treatment['purchase_0'] = treatment.purchase_month + 12 * (treatment.purchase_year - 2015) # Creating one unique time variable\n",
    "    treatment['closing_0'] = treatment.Closing_date.dt.month  + 12 * (treatment.Closing_date.dt.year - 2015)\n",
    "    treatment['interaction'] = treatment.purchase_0 >= treatment.closing_0 # The post dummy equals to one in the treatment group, after the closing month\n",
    "    treatment = treatment[abs(treatment.purchase_0-treatment.closing_0) > dropping_period]\n",
    "    treatment['effects'] = list(zip(treatment.store_state, treatment.purchase_0)) # Crontrolling for time * state\n",
    "\n",
    "\n",
    "\n",
    "    # Final dataset for the regression :\n",
    "    df = pd.concat((control, treatment))[['upc_price', 'treat', 'interaction', 'effects']]\n",
    "    df = df[df.upc_price != 0] # Dropping the errors in the set\n",
    "\n",
    "    try:\n",
    "        reg1 = smf.ols(formula='np.log(upc_price) ~ treat + interaction + C(effects)', data=df)\n",
    "        results1 = reg1.fit()\n",
    "\n",
    "        if abs(results1.params[2] / results1.bse[2]) > 2.:\n",
    "            print(f\"Coef : {np.exp(results1.params[2])-1}\")\n",
    "        print(f\"Coef/err : {abs(results1.params[2] / results1.bse[2])}\")\n",
    "\n",
    "    except:\n",
    "        print('Method does not converge')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
